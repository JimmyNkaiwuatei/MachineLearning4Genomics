{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominant-respect",
   "metadata": {},
   "source": [
    "## Feature Engineering in Genomics\n",
    "\n",
    "Feature Engineering is the process of transforming raw data into features/input variables that are easily digested by algorithms. People think that data scientists often spend most of their time testing out various algorithms; however, the majority of performance gains generally come from well-crafted features.\n",
    "\n",
    "While performing feature engineering, it is critical to keep in mind the question that you are trying to answer. For the purposes of this exercise, we will be using ...genomic data, with an aims to answer the following questions:\n",
    "\n",
    "\n",
    "In this notebook, we will introduce the following types of feature engineering:\n",
    "- Feature pruning\n",
    "- Time-based features (month, year, etc)\n",
    "- One-hot encoding to create dummy variables\n",
    "- Extracting features from strings\n",
    "- Feature scaling\n",
    "- Data imputation / cleaning\n",
    "\n",
    "How to transform your genomics data to fit into machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-myanmar",
   "metadata": {},
   "source": [
    "### Converting DNA Sequence String into NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "czech-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dna_sequence_np_array(dna_sequence_string):\n",
    "    dna_sequence_array = None\n",
    "    try:\n",
    "        dna_sequence_string = dna_sequence_string.lower()   \n",
    "        regex_acgt = re.compile('[^acgt]') \n",
    "        if (regex_acgt.search(dna_sequence_string) == None):           \n",
    "            dna_sequence_array = np.array(list(dna_sequence_string))\n",
    "        else:       \n",
    "            dna_sequence_array = None    \n",
    "    except:               \n",
    "        print(PyDNA.get_exception_info())\n",
    "        if PyDNA._app_is_log: PyDNA.write_log_file(\"error\",   PyDNA.get_exception_info())  \n",
    "    return dna_sequence_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "announced-summer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        module\n",
       "\u001b[0;31mString form:\u001b[0m <module 'pydna' from '/Users/caleb/opt/miniconda3/envs/malaria/lib/python3.9/site-packages/pydna/__init__.py'>\n",
       "\u001b[0;31mFile:\u001b[0m        ~/opt/miniconda3/envs/malaria/lib/python3.9/site-packages/pydna/__init__.py\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       ":copyright: Copyright 2013 - 2019 by Björn Johansson. All rights reserved.\n",
       ":license:   This code is part of the pydna package, governed by the\n",
       "            license in LICENSE.txt that should be included as part of this package.\n",
       "\n",
       "pydna\n",
       "=====\n",
       "Pydna is a python package providing code for simulation of the creation of recombinant DNA molecules\n",
       "using `molecular biology <https://en.wikipedia.org/wiki/Molecular_biology>`_ techniques.\n",
       "\n",
       "Provided:\n",
       "  1. PCR simulation\n",
       "  2. Assembly simulation based on shared identical sequences\n",
       "  3. Primer design for amplification of a given sequence\n",
       "  4. Automatic design of primer tails for Gibson assembly or homologous recombination.\n",
       "  5. Restriction digestion and cut&paste cloning\n",
       "  6. Agarose gel simulation\n",
       "  7. Download sequences from Genbank\n",
       "  8. Parsing various sequence formats including the capacity to handle broken Genbank format\n",
       "\n",
       "pydna package layout\n",
       "--------------------\n",
       "\n",
       "The most important modules and how to import functions or classes from them are listed below.\n",
       "Class names starts with a capital letter, functions with a lowercase letter:\n",
       "\n",
       "::\n",
       "\n",
       "      from pydna.module import function\n",
       "      from pydna.module import Class\n",
       "\n",
       "      Example: from pydna.gel import Gel\n",
       "\n",
       "      pydna\n",
       "         ├── amplify\n",
       "         │         ├── Anneal\n",
       "         │         └── pcr\n",
       "         ├── assembly\n",
       "         │          └── Assembly\n",
       "         ├── design\n",
       "         │        ├── assembly_fragments\n",
       "         │        └── primer_design\n",
       "         ├── download\n",
       "         │          └── download_text\n",
       "         ├── dseqrecord\n",
       "         │            └── Dseqrecord\n",
       "         ├── gel\n",
       "         │     └── Gel\n",
       "         ├── genbank\n",
       "         │         ├── genbank\n",
       "         │         └── Genbank\n",
       "         ├── parsers\n",
       "         │         ├── parse\n",
       "         │         └── parse_primers\n",
       "         └── readers\n",
       "                   ├── read\n",
       "                   └── read_primers\n",
       "\n",
       "\n",
       "\n",
       "How to use the documentation\n",
       "----------------------------\n",
       "Documentation is available as docstrings provided in the source code for each module.\n",
       "These docstrings can be inspected by reading the source code directly.\n",
       "See further below on how to obtain the code for pydna.\n",
       "\n",
       "In the python shell, use the built-in ``help`` function to view a function's docstring::\n",
       "\n",
       "  >>> from pydna import readers\n",
       "  >>> help(readers.read)\n",
       "  ... # doctest: +SKIP\n",
       "\n",
       "The doctrings are also used to provide an automaticly generated reference manual available online at\n",
       "`read the docs <https://pydna.readthedocs.io>`_.\n",
       "\n",
       "Docstrings can be explored using `IPython <http://ipython.org/>`_, an advanced Python shell with\n",
       "TAB-completion and introspection capabilities. To see which functions are available in `pydna`,\n",
       "type `pydna.<TAB>` (where `<TAB>` refers to the TAB key).\n",
       "Use `pydna.open_config_folder?<ENTER>`to view the docstring or `pydna.open_config_folder??<ENTER>` to view the source code.\n",
       "\n",
       "In the `Spyder IDE <https://github.com/spyder-ide/spyder>`_ it is possible to place the cursor immediately before\n",
       "the name of a module,class or function and press ctrl+i to bring up docstrings in a separate window in Spyder\n",
       "\n",
       "Code snippets are indicated by three greater-than signs::\n",
       "\n",
       "    >>> x=41\n",
       "    >>> x=x+1\n",
       "    >>> x\n",
       "    42\n",
       "\n",
       "pydna source code\n",
       "-----------------\n",
       "\n",
       "The pydna source code is `available on Github <https://github.com/BjornFJohansson/pydna>`_.\n",
       "\n",
       "How to get more help\n",
       "--------------------\n",
       "\n",
       "Please join the `Google grooup <https://groups.google.com/forum/#!forum/pydna>`_ for pydna, this is the preferred\n",
       "location for help. If you find bugs in pydna itself, open an issue at the `Github repository <https://github.com/BjornFJohansson/pydna/issues>`_.\n",
       "\n",
       "Examples of pydna in use\n",
       "------------------------\n",
       "\n",
       "See this repository for a collection of `examples <https://github.com/BjornFJohansson/pydna-examples>`_.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pydna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extraordinary-prague",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pydna' has no attribute 'dna_sequence_np_array'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f2c0fb4c8947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdna_sequence_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ATATATCCCGGGAATTTTCGTAGTTAGGCTGATTTTATTGGCGCGAAAATTTTTT\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdna_np_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdna_sequence_np_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdna_sequence_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdna_label_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdna_label_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdna_np_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DNA sequence string:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdna_sequence_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DNA NumPy array:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdna_np_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pydna' has no attribute 'dna_sequence_np_array'"
     ]
    }
   ],
   "source": [
    "dna_sequence_string = \"ATATATCCCGGGAATTTTCGTAGTTAGGCTGATTTTATTGGCGCGAAAATTTTTT\"\n",
    "dna_np_array = pydna.dna_sequence_np_array(dna_sequence_string) \n",
    "dna_label_encoder = pydna.dna_label_encoder(dna_np_array) \n",
    "print(\"DNA sequence string:\\n{}\".format(dna_sequence_string))\n",
    "print(\"DNA NumPy array:\\n{}\".format(dna_np_array))\n",
    "print(\"Custom Label Encoding:\\n{}\".format(dna_label_encoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-earth",
   "metadata": {},
   "source": [
    "## 1. Ordinal / Label Encoding\n",
    "this label (ordinary) encoding will encode each base nucleotide as a custom numerical value. Mostly use `'A':0.25, 'C':0.5,'G':0.75, 'T':1.0`, but sometimes may use `A':1, 'C':2,'G':3, 'T':4`, which is not recommended. \n",
    "\n",
    "Here is a custom code for label encoding. However, `sklearn` has an inbuilt encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-click",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "exceptional-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequence_string = \"ATATATCCCGGGAATTTTCGTAGTTAGGCTGATTTTATTGGCGCGAAAATTTTTT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "wrapped-attendance",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_dict_per = {'A':0.25, 'C':0.5,'G':0.75, 'T':1.0, 'N':0 }\n",
    "dna_dict_int = {'A':1, 'C':2,'G':3, 'T':4, 'N':0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "floral-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = [dna_dict[dna] for dna in list(dna_sequence_string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cooked-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "stylish-cambodia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "def string_to_array(seq_string):\n",
    "    seq_string = seq_string.lower()\n",
    "    seq_string = re.sub('[^acgt]', 'n', seq_string)\n",
    "    seq_string = np.array(list(seq_string))\n",
    "    return seq_string\n",
    "# create a label encoder with 'acgtn' alphabet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['a','c','g','t','z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "confused-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoder(my_array):\n",
    "    integer_encoded = label_encoder.transform(my_array)\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25 # A\n",
    "    float_encoded[float_encoded == 1] = 0.50 # C\n",
    "    float_encoded[float_encoded == 2] = 0.75 # G\n",
    "    float_encoded[float_encoded == 3] = 1.00 # T\n",
    "    float_encoded[float_encoded == 4] = 0.00 # anything else, lets say n\n",
    "    return float_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "understanding-upgrade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 1.  , 0.5 , 0.25, 0.75, 0.5 , 0.5 , 0.25, 0.75, 1.  , 0.75])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_test = 'TTCAGCCAGTG'\n",
    "ordinal_encoder(string_to_array(seq_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-congress",
   "metadata": {},
   "source": [
    "## 2. One hot Encoder\n",
    "For the standard base of nucleotides, the “ACGT” sequence string will be one-hot encoded as [[1. 0. 0. 0.] [0. 1. 0. 0.] [0. 0. 1. 0.] [0. 0. 0. 1.]] using the NumPy array [‘a’ ‘c’ ‘g’ ‘t’]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "narrative-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "\n",
    "class hot_dna:\n",
    "    def __init__(self,fasta):\n",
    "        #check for and grab sequence name\n",
    "        if re.search(\">\",fasta):\n",
    "            name = re.split(\"\\n\",fasta)[0]\n",
    "            sequence = re.split(\"\\n\",fasta)[1]\n",
    "        else :\n",
    "            name = 'unknown_sequence'\n",
    "            sequence = fasta\n",
    "  \n",
    "        #get sequence into an array\n",
    "        seq_array = array(list(sequence))\n",
    "    \n",
    "        #integer encode the sequence\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded_seq = label_encoder.fit_transform(seq_array)\n",
    "    \n",
    "        #one hot the sequence\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        #reshape because that's what OneHotEncoder likes\n",
    "        integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
    "        onehot_encoded_seq = onehot_encoder.fit_transform(integer_encoded_seq)\n",
    "\n",
    "        #add the attributes to self \n",
    "        self.name = name\n",
    "        self.sequence = fasta\n",
    "        self.integer = integer_encoded_seq\n",
    "        self.onehot = onehot_encoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fuzzy-round",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "together-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = \">fake_sequence\\nATGTGTCGTAGTCGTACG\"\n",
    "my_hottie = hot_dna(fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "knowing-usage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hottie.onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-recovery",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fifteen-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def one_hot_encoder(seq_string):\n",
    "    int_encoded = label_encoder.transform(seq_string)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
    "    int_encoded = int_encoded.reshape(len(int_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n",
    "    onehot_encoded = np.delete(onehot_encoded, -1, 1)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "sharp-sugar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_test = 'GAATTCTCGAA'\n",
    "one_hot_encoder(string_to_array(seq_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-northeast",
   "metadata": {},
   "source": [
    "## K-mer counting\n",
    "Another form of encoding, mostly used in Natioral langiage processing is k-mer counting. Here we can decide on the size of the k-mer and then count them in various sequences, then see how if that can correlate.\n",
    "\n",
    "We first take the long biological sequence and break it down into k-mer length overlapping “words”. For example, if we use “words” of length 6 (hexamers), “ATGCATGCA” becomes: ‘ATGCAT’, ‘TGCATG’, ‘GCATGC’, ‘CATGCA’. Hence our example sequence is broken down into 4 hexamer words.\n",
    "\n",
    "In genomics, we refer to these types of manipulations as [“k-mer counting”](https://en.wikipedia.org/wiki/K-mer), or counting the occurrences of each possible k-mer sequence and Python natural language processing tools make it super easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "wrong-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmers_funct(seq, size):\n",
    "    return [seq[x:x+size].lower() for x in range(len(seq) - size + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adjusted-bottle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gtgccca',\n",
       " 'tgcccag',\n",
       " 'gcccagg',\n",
       " 'cccaggt',\n",
       " 'ccaggtt',\n",
       " 'caggttc',\n",
       " 'aggttca',\n",
       " 'ggttcag',\n",
       " 'gttcagt',\n",
       " 'ttcagtg',\n",
       " 'tcagtga',\n",
       " 'cagtgag',\n",
       " 'agtgagt',\n",
       " 'gtgagtg',\n",
       " 'tgagtga',\n",
       " 'gagtgac',\n",
       " 'agtgaca',\n",
       " 'gtgacac',\n",
       " 'tgacaca',\n",
       " 'gacacag',\n",
       " 'acacagg',\n",
       " 'cacaggc',\n",
       " 'acaggca',\n",
       " 'caggcag']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySeq = 'GTGCCCAGGTTCAGTGAGTGACACAGGCAG'\n",
    "Kmers_funct(mySeq, size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-activity",
   "metadata": {},
   "source": [
    "We can the convert the kmers to words, and then use the natural language processing methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "charged-outline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtgccc tgccca gcccag cccagg ccaggt caggtt aggttc ggttca gttcag ttcagt tcagtg cagtga agtgag gtgagt tgagtg gagtga agtgac gtgaca tgacac gacaca acacag cacagg acaggc caggca aggcag'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Kmers_funct(mySeq, size=6)\n",
    "joined_sentence = ' '.join(words)\n",
    "joined_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "brave-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeq1 = 'TCTCACACATGTGCCAATCACTGTCACCC'\n",
    "mySeq2 = 'GTGCCCAGGTTCAGTGAGTGACACAGGCAG'\n",
    "sentence1 = ' '.join(Kmers_funct(mySeq1, size=6))\n",
    "sentence2 = ' '.join(Kmers_funct(mySeq2, size=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "composite-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform([joined_sentence, sentence1, sentence2]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "tested-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-collapse",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "We will not overwrite our dataframe with scaled values because the appropriate scaling technique depends on the algorithm.  These are the three most common feature scaling techniques:\n",
    "1. Normalization\n",
    "2. Standardization\n",
    "3. Log-transformation\n",
    "\n",
    "### Normalization -- Min-max scaling\n",
    "\n",
    "- Min-max scaling squashes the features into a [0, 1] range, which can be achieved via the following equation for a single input $i$:\n",
    "\n",
    "$$x^{[i]}_{\\text{norm}} = \\frac{x^{[i]} - x_{\\text{min}} }{ x_{\\text{max}} - x_{\\text{min}} }$$\n",
    "\n",
    "Normalization is the process of rescaling the data from 0-1.  The formula for this approach is:\n",
    "\n",
    "`X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) X_scaled = X_std * (max - min) + min` \n",
    "\n",
    "### Standardization\n",
    "\n",
    "- Z-score standardization is a useful standardization scheme if we are working with certain optimization methods (e.g., gradient descent). \n",
    "- After standardizing a feature, it will have the properties of a standard normal distribution, that is, unit variance and zero mean ($N(\\mu=0, \\sigma^2=1)$); however, this does not transform a feature from not following a normal distribution to a normal distributed one.\n",
    "- The formula for standardizing a feature is shown below, for a single data point $x^{[i]}$.\n",
    "\n",
    "$$x^{[i]}_{\\text{std}} = \\frac{x^{[i]} - \\mu_x }{ \\sigma_{x} }$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-offense",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
