{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indian-catholic",
   "metadata": {},
   "source": [
    "## Feature Engineering in Genomics\n",
    "\n",
    "Feature Engineering is the process of transforming raw data into features/input variables that are easily digested by algorithms. People think that data scientists often spend most of their time testing out various algorithms; however, the majority of performance gains generally come from well-crafted features.\n",
    "\n",
    "While performing feature engineering, it is critical to keep in mind the question that you are trying to answer. For the purposes of this exercise, we will be using ...genomic data, with an aims to answer the following questions:\n",
    "\n",
    "\n",
    "In this notebook, we will introduce the following types of feature engineering:\n",
    "- Feature pruning\n",
    "- Time-based features (month, year, etc)\n",
    "- One-hot encoding to create dummy variables\n",
    "- Extracting features from strings\n",
    "- Feature scaling\n",
    "- Data imputation / cleaning\n",
    "\n",
    "How to transform your genomics data to fit into machine learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-bachelor",
   "metadata": {},
   "source": [
    "### Converting DNA Sequence String into NumPy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-asian",
   "metadata": {},
   "source": [
    "## 1. Ordinal / Label Encoding\n",
    "this label (ordinary) encoding will encode each base nucleotide as a custom numerical value. Mostly use `'A':0.25, 'C':0.5,'G':0.75, 'T':1.0`, but sometimes may use `A':1, 'C':2,'G':3, 'T':4`, which is not recommended. \n",
    "\n",
    "Here is a custom code for label encoding. However, `sklearn` has an inbuilt encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aerial-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequence_string = \"ATATATCCCGGGAATTTTCGTAGTTAGGCTGATTTTATTGGCGCGAAAATTTTTT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "varied-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_dict_per = {'A':0.25, 'C':0.5,'G':0.75, 'T':1.0, 'N':0 }\n",
    "dna_dict_int = {'A':1, 'C':2,'G':3, 'T':4, 'N':0 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monetary-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encode = [dna_dict_per[dna] for dna in list(dna_sequence_string)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attractive-incentive",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.25,\n",
       " 1.0,\n",
       " 0.25,\n",
       " 1.0,\n",
       " 0.25,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 0.25,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.25,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.5,\n",
       " 1.0,\n",
       " 0.75,\n",
       " 0.25,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.25,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.75,\n",
       " 0.75,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 0.5,\n",
       " 0.75,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "silver-hunter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "def string_to_array(seq_string):\n",
    "    seq_string = seq_string.lower()\n",
    "    seq_string = re.sub('[^acgt]', 'n', seq_string)\n",
    "    seq_string = np.array(list(seq_string))\n",
    "    return seq_string\n",
    "# create a label encoder with 'acgtn' alphabet\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(np.array(['a','c','g','t','z']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "activated-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoder(my_array):\n",
    "    integer_encoded = label_encoder.transform(my_array)\n",
    "    float_encoded = integer_encoded.astype(float)\n",
    "    float_encoded[float_encoded == 0] = 0.25 # A\n",
    "    float_encoded[float_encoded == 1] = 0.50 # C\n",
    "    float_encoded[float_encoded == 2] = 0.75 # G\n",
    "    float_encoded[float_encoded == 3] = 1.00 # T\n",
    "    float_encoded[float_encoded == 4] = 0.00 # anything else, lets say n\n",
    "    return float_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "elect-chambers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 1.  , 0.5 , 0.25, 0.75, 0.5 , 0.5 , 0.25, 0.75, 1.  , 0.75])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_test = 'TTCAGCCAGTG'\n",
    "ordinal_encoder(string_to_array(seq_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-checklist",
   "metadata": {},
   "source": [
    "## 2. One hot Encoder\n",
    "For the standard base of nucleotides, the “ACGT” sequence string will be one-hot encoded as [[1. 0. 0. 0.] [0. 1. 0. 0.] [0. 0. 1. 0.] [0. 0. 0. 1.]] using the NumPy array [‘a’ ‘c’ ‘g’ ‘t’]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intelligent-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "\n",
    "class hot_dna:\n",
    "    def __init__(self,fasta):\n",
    "        #check for and grab sequence name\n",
    "        if re.search(\">\",fasta):\n",
    "            name = re.split(\"\\n\",fasta)[0]\n",
    "            sequence = re.split(\"\\n\",fasta)[1]\n",
    "        else :\n",
    "            name = 'unknown_sequence'\n",
    "            sequence = fasta\n",
    "  \n",
    "        #get sequence into an array\n",
    "        seq_array = array(list(sequence))\n",
    "    \n",
    "        #integer encode the sequence\n",
    "        label_encoder = LabelEncoder()\n",
    "        integer_encoded_seq = label_encoder.fit_transform(seq_array)\n",
    "    \n",
    "        #one hot the sequence\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        #reshape because that's what OneHotEncoder likes\n",
    "        integer_encoded_seq = integer_encoded_seq.reshape(len(integer_encoded_seq), 1)\n",
    "        onehot_encoded_seq = onehot_encoder.fit_transform(integer_encoded_seq)\n",
    "\n",
    "        #add the attributes to self \n",
    "        self.name = name\n",
    "        self.sequence = fasta\n",
    "        self.integer = integer_encoded_seq\n",
    "        self.onehot = onehot_encoded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-profession",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "incomplete-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta = \">fake_sequence\\nATGTGTCGTAGTCGTACG\"\n",
    "my_hottie = hot_dna(fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "reflected-cursor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_hottie.onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-oxygen",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "starting-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "def one_hot_encoder(seq_string):\n",
    "    int_encoded = label_encoder.transform(seq_string)\n",
    "    onehot_encoder = OneHotEncoder(sparse=False, dtype=int)\n",
    "    int_encoded = int_encoded.reshape(len(int_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(int_encoded)\n",
    "    onehot_encoded = np.delete(onehot_encoded, -1, 1)\n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accompanied-literature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_test = 'GAATTCTCGAA'\n",
    "one_hot_encoder(string_to_array(seq_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-summer",
   "metadata": {},
   "source": [
    "## K-mer counting\n",
    "Another form of encoding, mostly used in Natural language processing is k-mer counting. Here we can decide on the size of the k-mer and then count them in various sequences, then see how if that can correlate.\n",
    "\n",
    "We first take the long biological sequence and break it down into k-mer length overlapping “words”. For example, if we use “words” of length 6 (hexamers), “ATGCATGCA” becomes: ‘ATGCAT’, ‘TGCATG’, ‘GCATGC’, ‘CATGCA’. Hence our example sequence is broken down into 4 hexamer words.\n",
    "\n",
    "In genomics, we refer to these types of manipulations as [“k-mer counting”](https://en.wikipedia.org/wiki/K-mer), or counting the occurrences of each possible k-mer sequence and Python natural language processing tools make it super easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "spread-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kmers_funct(seq, k):\n",
    "    return [seq[x:x+k].lower() for x in range(len(seq) - k + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "coastal-measurement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gtgcc',\n",
       " 'tgccc',\n",
       " 'gccca',\n",
       " 'cccag',\n",
       " 'ccagg',\n",
       " 'caggt',\n",
       " 'aggtt',\n",
       " 'ggttc',\n",
       " 'gttca',\n",
       " 'ttcag',\n",
       " 'tcagt',\n",
       " 'cagtg',\n",
       " 'agtga',\n",
       " 'gtgag',\n",
       " 'tgagt',\n",
       " 'gagtg',\n",
       " 'agtga',\n",
       " 'gtgac',\n",
       " 'tgaca',\n",
       " 'gacac',\n",
       " 'acaca',\n",
       " 'cacag',\n",
       " 'acagg',\n",
       " 'caggc',\n",
       " 'aggca',\n",
       " 'ggcag']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mySeq = 'GTGCCCAGGTTCAGTGAGTGACACAGGCAG'\n",
    "Kmers_funct(mySeq, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-carnival",
   "metadata": {},
   "source": [
    "We can the convert the kmers to words, and then use the natural language processing methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "going-framework",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtgccc tgccca gcccag cccagg ccaggt caggtt aggttc ggttca gttcag ttcagt tcagtg cagtga agtgag gtgagt tgagtg gagtga agtgac gtgaca tgacac gacaca acacag cacagg acaggc caggca aggcag'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = Kmers_funct(mySeq, k=6)\n",
    "joined_sentence = ' '.join(words)\n",
    "joined_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "precise-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeq1 = 'TCTCACACATGTGCCAATCACTGTCACCCTCTCACACA'\n",
    "mySeq2 = 'GTGCCCAGGTTCAGTGAGTGACACAGGCAGTCTCACACA'\n",
    "sentence1 = ' '.join(Kmers_funct(mySeq1, k=6))\n",
    "sentence2 = ' '.join(Kmers_funct(mySeq2, k=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "equivalent-checklist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tctcac ctcaca tcacac cacaca acacat cacatg acatgt catgtg atgtgc tgtgcc gtgcca tgccaa gccaat ccaatc caatca aatcac atcact tcactg cactgt actgtc ctgtca tgtcac gtcacc tcaccc caccct accctc ccctct cctctc ctctca tctcac ctcaca tcacac cacaca'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "treated-birth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gtgccc tgccca gcccag cccagg ccaggt caggtt aggttc ggttca gttcag ttcagt tcagtg cagtga agtgag gtgagt tgagtg gagtga agtgac gtgaca tgacac gacaca acacag cacagg acaggc caggca aggcag ggcagt gcagtc cagtct agtctc gtctca tctcac ctcaca tcacac cacaca'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "nutritional-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform([joined_sentence, sentence1, sentence2]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "competent-thunder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "        0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       "       [1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 2, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 1, 1, 2, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 2, 1, 1, 0, 2, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-producer",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "We will not overwrite our dataframe with scaled values because the appropriate scaling technique depends on the algorithm.  These are the three most common feature scaling techniques:\n",
    "1. Normalization\n",
    "2. Standardization\n",
    "3. Log-transformation\n",
    "\n",
    "### Normalization -- Min-max scaling\n",
    "\n",
    "- Min-max scaling squashes the features into a [0, 1] range, which can be achieved via the following equation for a single input $i$:\n",
    "\n",
    "$$x^{[i]}_{\\text{norm}} = \\frac{x^{[i]} - x_{\\text{min}} }{ x_{\\text{max}} - x_{\\text{min}} }$$\n",
    "\n",
    "Normalization is the process of rescaling the data from 0-1.  The formula for this approach is:\n",
    "\n",
    "`X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) X_scaled = X_std * (max - min) + min` \n",
    "\n",
    "### Standardization\n",
    "\n",
    "- Z-score standardization is a useful standardization scheme if we are working with certain optimization methods (e.g., gradient descent). \n",
    "- After standardizing a feature, it will have the properties of a standard normal distribution, that is, unit variance and zero mean ($N(\\mu=0, \\sigma^2=1)$); however, this does not transform a feature from not following a normal distribution to a normal distributed one.\n",
    "- The formula for standardizing a feature is shown below, for a single data point $x^{[i]}$.\n",
    "\n",
    "$$x^{[i]}_{\\text{std}} = \\frac{x^{[i]} - \\mu_x }{ \\sigma_{x} }$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-passport",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
